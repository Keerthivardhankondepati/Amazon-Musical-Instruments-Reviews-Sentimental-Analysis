{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing all necessarry packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reading JSON file into Pandas DataFrame\n",
    "\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield json.dumps(eval(l))\n",
    "\n",
    "f = open(\"output.strict\", 'w')\n",
    "for l in parse(r\"C:\\Users\\Eswar\\Desktop\\Hackathon\\Music.json.gz\"):\n",
    "    f.write(l + '\\n')\n",
    "\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF(r'C:\\Users\\Eswar\\Desktop\\Hackathon\\Music.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use=df[['reviewText']]  # creating df_use data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending positive and Negetive labels based on Overall Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eswar\\New folder\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "result = [] \n",
    "for value in df[\"overall\"]: \n",
    "    if value == 1.0: \n",
    "        result.append(\"Negative\") \n",
    "    elif value==2.0: \n",
    "        result.append(\"Negative\") \n",
    "    elif value==3.0: \n",
    "        result.append(\"Neutral\")\n",
    "    elif value==4.0: \n",
    "        result.append(\"Positive\")\n",
    "    elif value==5.0: \n",
    "        result.append(\"Positive\")\n",
    "       \n",
    "df_use[\"Result\"] = result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10256</td>\n",
       "      <td>Great, just as expected.  Thank to all.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10257</td>\n",
       "      <td>I've been thinking about trying the Nanoweb st...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10258</td>\n",
       "      <td>I have tried coated strings in the past ( incl...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10259</td>\n",
       "      <td>Well, MADE by Elixir and DEVELOPED with Taylor...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10260</td>\n",
       "      <td>These strings are really quite good, but I wou...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10261 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText    Result\n",
       "0      Not much to write about here, but it does exac...  Positive\n",
       "1      The product does exactly as it should and is q...  Positive\n",
       "2      The primary job of this device is to block the...  Positive\n",
       "3      Nice windscreen protects my MXL mic and preven...  Positive\n",
       "4      This pop filter is great. It looks and perform...  Positive\n",
       "...                                                  ...       ...\n",
       "10256            Great, just as expected.  Thank to all.  Positive\n",
       "10257  I've been thinking about trying the Nanoweb st...  Positive\n",
       "10258  I have tried coated strings in the past ( incl...  Positive\n",
       "10259  Well, MADE by Elixir and DEVELOPED with Taylor...  Positive\n",
       "10260  These strings are really quite good, but I wou...  Positive\n",
       "\n",
       "[10261 rows x 2 columns]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Neutral results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use=df_use.loc[df_use['Result']!='Neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics of Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9489, 2)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling to increase negetive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "y = df_use.Result\n",
    "X = df_use.drop('Result', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "not_fraud = X[X.Result=='Positive']\n",
    "fraud = X[X.Result=='Negative']\n",
    "fraud_upsampled = resample(fraud,replace=True,n_samples=len(not_fraud), random_state=27) \n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "#upsampled.Result.value_counts()  # To check sampled values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>728</td>\n",
       "      <td>I like the fact that it can be &amp;#34;partially&amp;...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5825</td>\n",
       "      <td>This thing is amazing. Like many I cannot affo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>I love these strings, and use them for all of ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7846</td>\n",
       "      <td>Love these things.I feel a little guilty becau...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2683</td>\n",
       "      <td>I have stayed clear of using pedals for most o...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8147</td>\n",
       "      <td>I ordered this from the Amazon warehouse as a ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3083</td>\n",
       "      <td>All I gotta say about  this product is that I ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3987</td>\n",
       "      <td>Cheap crappy strap. It's too stiff, not comfor...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3192</td>\n",
       "      <td>Need 2 volume knobs and 1 tone, so for the pri...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3199</td>\n",
       "      <td>I've ordered two of these kits in the aged whi...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13546 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText    Result\n",
       "728   I like the fact that it can be &#34;partially&...  Positive\n",
       "5825  This thing is amazing. Like many I cannot affo...  Positive\n",
       "321   I love these strings, and use them for all of ...  Positive\n",
       "7846  Love these things.I feel a little guilty becau...  Positive\n",
       "2683  I have stayed clear of using pedals for most o...  Positive\n",
       "...                                                 ...       ...\n",
       "8147  I ordered this from the Amazon warehouse as a ...  Negative\n",
       "3083  All I gotta say about  this product is that I ...  Negative\n",
       "3987  Cheap crappy strap. It's too stiff, not comfor...  Negative\n",
       "3192  Need 2 volume knobs and 1 tone, so for the pri...  Negative\n",
       "3199  I've ordered two of these kits in the aged whi...  Negative\n",
       "\n",
       "[13546 rows x 2 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting testing and traning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(upsampled['reviewText'], upsampled['Result'], test_size=0.25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting positive / Negetive labels to 1/0\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test  = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3387,)\n",
      "(10159,)\n",
      "(3387,)\n",
      "(10159,)\n"
     ]
    }
   ],
   "source": [
    "# Checking size of training and testing samples\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TF-IDF to convert text to Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word',  token_pattern=r'\\w{2,}', max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_fit_tra = tfidf_vect.fit_transform(X_train).toarray()     # Fit-transform of Train data\n",
    "\n",
    "tfidf_fit_tra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eswar\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegression()\n",
    "\n",
    "y_train=y_train.astype('int')            # converting to int\n",
    "\n",
    "logreg.fit(tfidf_fit_tra, y_train)       #Fitting Logistic Regression on Training data\n",
    "\n",
    "tfidf_fit_tra_test=tfidf_vect.fit_transform(X_test)   # Transforming Test data according to TF-IDF fit\n",
    "\n",
    "y_pred = logreg.predict(tfidf_fit_tra_test)          #Predicting values on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Checking predicted and actual\n",
    "\n",
    "print(y_pred[80])\n",
    "print(y_test[80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy by applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6303513433717154"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing Confusion Matrix and different performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1080,  616],\n",
       "       [ 636, 1055]], dtype=int64)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63      1696\n",
      "           1       0.63      0.62      0.63      1691\n",
      "\n",
      "    accuracy                           0.63      3387\n",
      "   macro avg       0.63      0.63      0.63      3387\n",
      "weighted avg       0.63      0.63      0.63      3387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(tfidf_fit_tra, y_train)\n",
    "\n",
    "y_pred = mnb.predict(tfidf_fit_tra_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5961027457927369"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1247,  449],\n",
       "       [ 919,  772]], dtype=int64)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.74      0.65      1696\n",
      "           1       0.63      0.46      0.53      1691\n",
      "\n",
      "    accuracy                           0.60      3387\n",
      "   macro avg       0.60      0.60      0.59      3387\n",
      "weighted avg       0.60      0.60      0.59      3387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \" very weak, worst quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_fit_tra_test1=tfidf_vect.transform([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted [0]\n"
     ]
    }
   ],
   "source": [
    "print('predicted',mnb.predict(tfidf_fit_tra_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted [0]\n"
     ]
    }
   ],
   "source": [
    "print('predicted',logreg.predict(tfidf_fit_tra_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
